{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RenatodaCostaSantos/Data_science_projects/blob/main/Predicting_cadiovascular_disease.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMHZrzI7B_pw"
      },
      "source": [
        "# Predicting cardiovascular disease\n",
        "\n",
        "According to the [World Health Organization (WHO)](https://www.who.int/health-topics/cardiovascular-diseases), 17.9 million people die of cardiovascular diseases (CVDs) every year.\n",
        "\n",
        "Poor diet, lack of physical activities, and mental health can increase the risk for CVDs. Identifying it in advance can save lives.\n",
        "\n",
        "We will use one of Kaggle's [dataset](https://www.kaggle.com/datasets/fedesoriano/heart-failure-prediction?resource=download) that contains personal and medical information from patients. The description of each column of the data is:\n",
        "\n",
        "1 - Age: age of the patient [years]\n",
        "\n",
        "2 - Sex: sex of the patient [M: Male, F: Female]\n",
        "\n",
        "3 - ChestPainType: chest pain type [TA: Typical Angina, ATA: Atypical Angina, NAP: Non-Anginal Pain, ASY: Asymptomatic]\n",
        "\n",
        "4 - RestingBP: resting blood pressure [mm Hg]\n",
        "\n",
        "5 - Cholesterol: serum cholesterol [mm/dl]\n",
        "\n",
        "6 - FastingBS: fasting blood sugar [1: if FastingBS > 120 mg/dl, 0: otherwise]\n",
        "\n",
        "7 - RestingECG: resting electrocardiogram results [Normal: Normal, ST: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV), LVH: showing probable or definite left ventricular hypertrophy by Estes' criteria]\n",
        "\n",
        "8 - MaxHR: maximum heart rate achieved [Numeric value between 60 and 202]\n",
        "\n",
        "9 - ExerciseAngina: exercise-induced angina [Y: Yes, N: No]\n",
        "\n",
        "10 - Oldpeak: oldpeak = ST [Numeric value measured in depression]\n",
        "\n",
        "11 - ST_Slope: the slope of the peak exercise ST segment [Up: upsloping, Flat: flat, Down: downsloping]\n",
        "\n",
        "12 - HeartDisease: output class [1: heart disease, 0: Normal]\n",
        "\n",
        "\n",
        "## Purpose of this project\n",
        "\n",
        "The main purpose of this project is to demonstrate how to perform binary classification in machine learning using the K-nearest neighbors algorithm and logistic regression. The dataset we will use is from real patients, however, the original multi-class labels for the target variable were transformed into binary outcomes.\n",
        "\n",
        "\n",
        "We start by exploring the data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOSI_tWSCg2z"
      },
      "source": [
        "## Data exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1Q_gycRGlHa",
        "outputId": "f6cf9a86-a598-4080-80b0-fbb6ad6618fc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJBc8eKnG2lR"
      },
      "outputs": [],
      "source": [
        "heart_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/heart.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "z3nNxUkxH43h",
        "outputId": "131c62a5-bd63-444e-e684-a526efec499b"
      },
      "outputs": [],
      "source": [
        "heart_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eLshKx2H71W",
        "outputId": "b306da48-e93c-408b-ba60-ac6f905ca5b5"
      },
      "outputs": [],
      "source": [
        "heart_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsAOBOqaIFyW"
      },
      "source": [
        "The dataset contains 918 observations and 12 columns. The target is the HeartDisease column, while the other 11 columns are features.\n",
        "\n",
        "The dataset contains some categorical features that will have to be transformed into numeric ones before we start with machine learning:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c96wsztHIdCK",
        "outputId": "ffa1c867-0fd9-42bf-9ef3-1d7dc7ec975b"
      },
      "outputs": [],
      "source": [
        "heart_df.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3U6vPwChJJHR"
      },
      "source": [
        "We will first explore the numerical columns:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "W3p5DRyAJr9w",
        "outputId": "35121e79-7f94-4968-e191-988ba21aee56"
      },
      "outputs": [],
      "source": [
        "# Check the summary statistics\n",
        "heart_df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayXqn5AhJ11d"
      },
      "source": [
        "Some observations:\n",
        "\n",
        "- The mean age for the patients is 53.5 years, while the median is 54 years old, indicating that the age distribution is slightly left-skewed.\n",
        "\n",
        "- The median for the Cholesterol column is higher than the mean, indicating a left-skewed distribution.\n",
        "\n",
        "- The minimum value for RestingBP, Cholesterol, and FastingBS is equal to zero. [Domain expertise](https://www.heart.org/en/health-topics/cholesterol/about-cholesterol/what-your-cholesterol-levels-mean) states that serum cholesterol:\n",
        "\n",
        "''*is a composite of different measurements. Your total blood cholesterol is calculated by adding your HDL and LDL cholesterol levels, plus 20% of your triglyceride level*''. That means we must clean zero values for this column later on.\n",
        "\n",
        "- The mean for the target variable is 0.55. It suggests that the outcomes (0 or 1) are roughly evenly distributed.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_jz-6jtPR2Q"
      },
      "source": [
        "### Numerical variables\n",
        "\n",
        "Let's visualize the distributions for the features. We start with the numerical variables:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IipKO0DdTfnO"
      },
      "source": [
        "#### Age feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aye0eMxZLOeK",
        "outputId": "f0065cc5-ab96-45f2-a9d0-5f3c18d9a0fb"
      },
      "outputs": [],
      "source": [
        "# Histogram for Age feature\n",
        "sns.histplot(data = heart_df, x = 'Age', hue=\"HeartDisease\", multiple=\"stack\").set(title = 'Distribution of patients age')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFFWC6_mPbKd"
      },
      "source": [
        "As common knowledge suggests, the distribution is left-skewed, meaning the majority of patients belong to the high-age side of the distribution (people over 50 years old).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKnnsp5lUjl2"
      },
      "source": [
        "#### Resting blood pressure feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gsquaaSLzvl",
        "outputId": "4cc755d1-c62e-4e84-d7ae-195ff39464af"
      },
      "outputs": [],
      "source": [
        "# Histogram for RestingBP\n",
        "sns.histplot(data = heart_df, x = 'RestingBP', hue=\"HeartDisease\", multiple=\"stack\").set(title = 'Distribution for patients resting blood pressure')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzw0zR1IMKLs"
      },
      "source": [
        "- The zero value for RestingBP is wrong. Only a dead person would have a null resting blood pressure, so we must clean it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-cci1W7Y4Db"
      },
      "source": [
        "#### Cholesterol feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcbRm3XgMucW",
        "outputId": "f4520f5f-d7a2-46b8-9929-557526dea8de"
      },
      "outputs": [],
      "source": [
        "# Histogram for Cholesterol\n",
        "sns.histplot(data = heart_df, x = 'Cholesterol', hue=\"HeartDisease\", multiple=\"stack\").set(title = 'Patients cholesterol distribution')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsfddqGzNaug"
      },
      "source": [
        "- There are many patients with zero cholesterol. We already knew from the summary statistics of the data that some of them would be zero, but now it is clear how many.\n",
        "\n",
        "- The mean and median values suggested a left-skewed distribution (when the median is higher than the mean). However, if we exclude zeros, the distribution looks like a right-skewed distribution. \n",
        "\n",
        "- It is not possible to have people with zero cholesterol. We must clean those values later on. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soguhfgPY9be"
      },
      "source": [
        "#### Maximum heart rate feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hlzc0jT7O-p1",
        "outputId": "3f3b2cd6-747c-42a6-f20d-6450b0ba4adf"
      },
      "outputs": [],
      "source": [
        "# Histogram for MaxHR\n",
        "sns.histplot(data = heart_df, x = 'MaxHR', hue=\"HeartDisease\", multiple=\"stack\").set(title = \"Maximum heart rate distribution\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X54XRLPWcKkZ"
      },
      "source": [
        "- The distribution for the maximum heart rate is slightly left-skewed. \n",
        "\n",
        "- The lower the maximum heart rate, the more likely a patient is positive for CVD. That's probably because the patients felt some discomfort as soon as the heart rate started increasing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWX7dl9DZEFg"
      },
      "source": [
        "#### Oldpeak feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeN0tWC2PRjH",
        "outputId": "85c83182-a0c9-4ec0-c186-6891810953cd"
      },
      "outputs": [],
      "source": [
        "# Histogram for Oldpeak\n",
        "sns.histplot(data= heart_df, x = 'Oldpeak', hue=\"HeartDisease\", multiple=\"stack\").set(title='Oldpeak distribution')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMc85MHCPncX"
      },
      "source": [
        "- The oldpeak definition is the ST depression induced by exercise relative\n",
        "to rest. Values for ST depression that are < -0.5 or > 0.5 are a good indicator that something is wrong. In fact, [ST depression greater than 1 mm is often a sign of myocardial ischemia or angina](https://www.ncbi.nlm.nih.gov/books/NBK549803/).\n",
        "\n",
        "- The histogram above shows explicitly what the domain knowledge suggested.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LATtGr_dc1X"
      },
      "source": [
        "### Categorical variables\n",
        "\n",
        "To visualize which categories are correlated with heart disease, we will plot some histograms for the categorical variables grouped by the patients diagnosed with CVD.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2kTcAmxSGpa"
      },
      "source": [
        "#### FastingBS feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0u4jinqdl6g",
        "outputId": "fdbe6cc9-914c-48c1-9c21-992e293f0f79"
      },
      "outputs": [],
      "source": [
        "# Histogram for FastingBS\n",
        "sns.histplot(data = heart_df, y = 'FastingBS', hue=\"HeartDisease\", multiple=\"stack\").set(title = 'Number of patients with high blood sugar concentration after fasting \\n (1 if it was higher than 120 mg/dl, 0 otherwise)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EmxWLvNdl6l"
      },
      "source": [
        "- Most people have less than 120 mg/dl of sugar in their blood. \n",
        "\n",
        "- [Domain knowledge](https://www.cdc.gov/diabetes/library/features/diabetes-and-heart.html) establishes a correlation between the level of sugar in one's blood and the risk for CVDs.\n",
        "\n",
        "- More than 50% of patients with high fasting blood sugar were diagnosed with heart disease."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pv_ILKunSQoG"
      },
      "source": [
        "#### Sex feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtrmMl0DuUE6",
        "outputId": "50cbad59-5a65-4f41-cd0c-4db67a0ef9ee"
      },
      "outputs": [],
      "source": [
        "# Histogram for Sex variable\n",
        "sns.histplot(data = heart_df, x = 'Sex', hue=\"HeartDisease\", multiple=\"stack\").set(title = 'Number of females and males')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsi41puffekQ"
      },
      "source": [
        "- Most of the patients in this dataset are males. \n",
        "\n",
        "- [Domain knowledge](https://www.health.harvard.edu/heart-health/throughout-life-heart-attacks-are-twice-as-common-in-men-than-women) establishes that men are twice more likely to develop heart diseases than women. [It also suggests that men tend to develop heart diseases ten years earlier than women](https://www.hopkinsmedicine.org/health/wellness-and-prevention/special-heart-risks-for-men). \n",
        "\n",
        "- According to the histogram above, ~ 63% of men were positive for CVDs, while ~ 25% of women were positive. In other words, men are roughly 2.5 times more likely to suffer from heart disease. Given that this is a small sample, it corroborates with domain knowledge.\n",
        "\n",
        "- The uneven distribution for men than women can induce bias in machine learning modeling. We need to be aware of that later on.\n",
        "\n",
        "\n",
        "What if we choose only people over 50 years old?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EWPjVFfOP_p",
        "outputId": "31dc7eda-d6ad-4cc1-c053-cc9e90d75238"
      },
      "outputs": [],
      "source": [
        "# Histogram for patients > 50 years old\n",
        "sns.histplot(data = heart_df[heart_df['Age']> 50], x = 'Sex', hue = 'HeartDisease', multiple = 'stack').set(title = 'Patients over 50 years old')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmUv7_ZaPUys",
        "outputId": "fd2f3978-ac97-4629-9942-778772494952"
      },
      "outputs": [],
      "source": [
        "# Number for males over fifty grouped by the target variable\n",
        "heart_df[(heart_df['Age']> 50) & (heart_df['Sex'] == 'M')].groupby(['HeartDisease']).sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVP2VHFgRBAb",
        "outputId": "de271c61-89e5-4772-a1b2-d0fca6b67dde"
      },
      "outputs": [],
      "source": [
        "# Number for females over fifty grouped by the target variable\n",
        "heart_df[(heart_df['Age']> 50) & (heart_df['Sex'] == 'F')].groupby(['HeartDisease']).sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuNvXEgmPTco"
      },
      "source": [
        "The percentage of men over 50 years old diagnosed with CVD is around 71%, while only ~34% of women were diagnosed with CVD. It also corroborates with domain knowledge."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mBQcfOgd2YW",
        "outputId": "3d2a98d2-c6ed-4096-d595-6579ef14915e"
      },
      "outputs": [],
      "source": [
        "# Distribution for the Sex variable\n",
        "heart_df['Sex'].value_counts(normalize = True)*100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z179fBcGhUM2"
      },
      "source": [
        "- Around 79% of the patients are male in this sample.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05NdOTKDSgn_"
      },
      "source": [
        "#### Chest pain feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQA5dtMShZRN",
        "outputId": "2558a2c0-975a-48b9-9652-d89b22f6b742"
      },
      "outputs": [],
      "source": [
        "# Histogram for ChestPainType\n",
        "sns.histplot(data = heart_df, x = 'ChestPainType', hue=\"HeartDisease\", multiple=\"stack\").set(title = 'Number of patients with different types of chest pain')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wG4A6w16hl6r"
      },
      "source": [
        "- Most of the patients were asymptomatic. The other three types of chest pain stand for:\n",
        "\n",
        "ATA - Atypical Angina\n",
        "\n",
        "TA: Typical Angina, \n",
        "\n",
        "NAP: Non-Anginal Pain.\n",
        "\n",
        "- Angina chest pain is caused by reduced blood flow to the heart. [It is often described as squeezing, pressure, heaviness, tightness, or pain in the chest](https://www.mayoclinic.org/diseases-conditions/angina/symptoms-causes/syc-20369373).\n",
        "\n",
        "- Around 50% of the typical angina patients are positive, while a smaller proportion of the non-anginal or atypical angina pain ends up being positive patients.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMw2cE0NSvK_"
      },
      "source": [
        "#### RestingECG feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_NrLWw-iAOK",
        "outputId": "0dafe6f6-4747-43b8-f19e-2398989ebbdd"
      },
      "outputs": [],
      "source": [
        "# Histogram for RestingECG\n",
        "sns.histplot(data = heart_df, x = 'RestingECG', hue=\"HeartDisease\", multiple=\"stack\").set(title = 'Distribution of resting electrocardiogram results')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QY9e03soc4E"
      },
      "source": [
        "- Most patients showed no abnormalities on the resting electrocardiogram results. However, ~50% of them were still positive for CVD.\n",
        "\n",
        "- Less than 200 patients had an ST positive result, meaning ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV). Also, less than 200 patients were positive for left ventricular hypertrophy (LVH), showing probable or definite LVH by Estes' criteria.\n",
        "\n",
        "- The data shows that a patient with an ST positive result has a slightly higher chance of being diagnosed with CVD than patients with a left ventricular hypertrophy positive result."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhvxfBSLSyD_"
      },
      "source": [
        "#### ExerciseAngina feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUCDJ5BXiZh_",
        "outputId": "13a9f63b-2254-4b29-f049-3df00e1cfa47"
      },
      "outputs": [],
      "source": [
        "# Histogram for ExerciseAngina\n",
        "sns.histplot(data = heart_df, x = 'ExerciseAngina', hue=\"HeartDisease\", multiple=\"stack\").set(title = 'Results for angina induced while exercising')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0_nAO4uBoQ-"
      },
      "source": [
        "- More than 500 patients did not suffer from pain while exercising.\n",
        "\n",
        "- Patients that developed angina while exercising are very likely to suffer from heart disease."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpLewTUjTCXe"
      },
      "source": [
        "#### ST_Slope feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYwU9zQniscS",
        "outputId": "b4ea23e0-35e9-4ddb-be58-3b16582096de"
      },
      "outputs": [],
      "source": [
        "# Histogram for ST_Slope\n",
        "sns.histplot(data = heart_df, x ='ST_Slope', hue=\"HeartDisease\", multiple=\"stack\").set(title = 'Slope of the peak exercise ST segment')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekQuse8_CxHd"
      },
      "source": [
        "- [Domain knowledge](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1123032/) establishes that patients showing a downsloping ST segment depression have a high probability of coronary disease.\n",
        "\n",
        "- The data corroborate with domain knowledge. It also shows that patients with a flat slope of the ST segment at peak exercise have a higher correlation with CVD.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyxquzdbTFpR"
      },
      "source": [
        "#### Target variable (HeartDisease)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ek3Hz3gPzt7",
        "outputId": "87f09ba2-7874-4b83-8e82-b75d737f15bb"
      },
      "outputs": [],
      "source": [
        "# Histogram for HeartDisease\n",
        "sns.histplot(data = heart_df, y = 'HeartDisease').set(title = 'Target variable results \\n (1 for sick, 0 otherwise)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olgzL_4ldiH2"
      },
      "source": [
        "The target variable seems roughly evenly distributed. Let's check the percentage:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uX-Nn4sodwF_",
        "outputId": "a10e59cd-7377-4622-8dae-2d40b3352e5b"
      },
      "outputs": [],
      "source": [
        "# Distribution of positive and negative values for the target variable\n",
        "heart_df['HeartDisease'].value_counts(normalize = True)*100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EOrirHKi4L1"
      },
      "source": [
        "## Missing values\n",
        "\n",
        "Let's check if there are any missing values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPoBl09KjTxG",
        "outputId": "851f4a90-d8d1-4bf3-f0ef-4c456de65612"
      },
      "outputs": [],
      "source": [
        "heart_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAaBMSrnjYA8"
      },
      "source": [
        "No action needed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QL2i9wYmQmEh"
      },
      "source": [
        "## Data cleaning\n",
        "\n",
        "The data exploration showed that there are no missing values. However, some values in the 'Cholesterol' and 'RestingBP' features need to be modified. Let's look at them: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGmPuFg4Q-zb",
        "outputId": "b29ba01c-bd9a-4839-a972-148cc039216f"
      },
      "outputs": [],
      "source": [
        "# Patients with zero resting blood pressure\n",
        "heart_df[heart_df['RestingBP'] < 10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4RspTcvRnbd",
        "outputId": "a335b75d-d460-4977-9cf2-b20360c8332e"
      },
      "outputs": [],
      "source": [
        "# Patients with zero cholesterol\n",
        "heart_df[heart_df['Cholesterol'] == 0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgxwP89eRy0E"
      },
      "source": [
        "Only one patient has zero resting blood pressure and 172 patients have null results for the cholesterol.\n",
        "\n",
        "The most common ways to replace data like that are:\n",
        "\n",
        "- Delete values if the number of rows is small compared to the dataset size.\n",
        "\n",
        "- Replace the values with the mean of the distribution when the number of rows is relatively high.\n",
        "\n",
        "- Replace the values with the mean of the distribution after grouping it, for example, using the age feature or any other feature that might be relevant according to the data.\n",
        "\n",
        "We will use the last approach, which will probably keep the overall quality of the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oIMxdx-QWfab"
      },
      "outputs": [],
      "source": [
        "# Creating a dataset for male and female patients\n",
        "male = heart_df[heart_df['Sex'] == 'M']\n",
        "female = heart_df[heart_df['Sex'] == 'F']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFE2Y2RZXgaV",
        "outputId": "5c35022d-34aa-42bb-8ad3-be7414df9b33"
      },
      "outputs": [],
      "source": [
        "male.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gw58tf6vXi-q",
        "outputId": "40228887-b69b-4928-b3ed-1fd12f3519ad"
      },
      "outputs": [],
      "source": [
        "female.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCAXBkq8X4AH"
      },
      "source": [
        "- The maximum and the minimum age for men are, respectively, 77 and 28 years old. That means a gap of 49 years between the maximum and the minimum values. We will divide the male patients into intervals of 7 years each.\n",
        "\n",
        "- For the women, the maximum age is 76 while the minimum is 30, and we will also split this dataset into intervals of 7 years."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6YBFvrAJco2F"
      },
      "outputs": [],
      "source": [
        "# Let's make a copy of the dataframe before replacing the data\n",
        "heartDF = heart_df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cmlJyGvW24D"
      },
      "outputs": [],
      "source": [
        "# Calculate the median for different age intervals for male patients\n",
        "men_list = [28,35,42,49,56,63,70]\n",
        "for age in men_list:\n",
        "  median = male.loc[(male['Age'] >= age) & (male['Age'] <= age + 7) & (male['Cholesterol'] != 0),'Cholesterol'].median()\n",
        "  heartDF.loc[(heartDF['Sex'] == 'M') & (heartDF['Age'] >= age) & (heartDF['Age'] <= age + 7) & (heartDF['Cholesterol'] == 0), 'Cholesterol'] = median"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6emBqeHilD1"
      },
      "outputs": [],
      "source": [
        "# Calculate the median for different age intervals for female patients\n",
        "women_list = [30,37,44,51,58,65,72]\n",
        "for age in women_list:\n",
        "  median = female.loc[(female['Age'] >= age) & (female['Age'] <= age + 7) & (female['Cholesterol'] != 0),'Cholesterol'].median()\n",
        "  try:\n",
        "    heartDF.loc[(heartDF['Sex'] == 'F') & (heartDF['Age'] >= age) & (heartDF['Age'] <= age + 7) & (heartDF['Cholesterol'] == 0), 'Cholesterol'] = median\n",
        "  except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HobVlDBzmVuT"
      },
      "source": [
        "For the zero value for resting blood pressure, we will also use the median of the same groups defined above:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z5DHYOWkmiyM"
      },
      "outputs": [],
      "source": [
        "# Replacing zero value for the only zero blood pressure patient\n",
        "median = male.loc[(male['Age'] >= 49) & (male['Age'] <= 56) & (male['RestingBP'] != 0),'RestingBP'].median()\n",
        "heartDF.loc[449, 'RestingBP'] = median"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqAl6ltDnhAs",
        "outputId": "df57ae44-2076-4d08-cada-18ca0520289e"
      },
      "outputs": [],
      "source": [
        "heartDF.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfC_D6WqjbX4"
      },
      "source": [
        "All values were correctly replaced. Let's visualize the distributions for these two variables once more:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjKzHuZZoPfd",
        "outputId": "71c3bef7-2a81-420a-a7d9-879326a58985"
      },
      "outputs": [],
      "source": [
        "# Histogram for RestingBP\n",
        "sns.histplot(data = heartDF, x = 'RestingBP', hue=\"HeartDisease\", multiple=\"stack\").set(title = 'Distribution for patients rest blood pressure')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ip8caBQEZcsY"
      },
      "source": [
        "- The median for this distribution is smaller than the mean, indicating a right-skewed distribution, as we predicted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOAb69b6oPff",
        "outputId": "eb49dbba-b5a5-43c8-92f6-f0cb74b72b63"
      },
      "outputs": [],
      "source": [
        "# Histogram for Cholesterol\n",
        "sns.histplot(data = heartDF, x = 'Cholesterol', hue=\"HeartDisease\", multiple=\"stack\").set(title = 'Patients cholesterol distribution')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6m42N5yjc00"
      },
      "source": [
        "## Feature selection\n",
        "\n",
        "Let's compute Pearson's r coefficient and search for linear correlations between the features and the target variable. That can serve as a guide to choosing good features for machine learning later on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaiEeCjKjvdN",
        "outputId": "0dda4f66-cd0f-407b-855e-7794d7366520"
      },
      "outputs": [],
      "source": [
        "abs(heartDF.corr()['HeartDisease']).nlargest(n=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTnu2-KqmaL6"
      },
      "source": [
        "From the exploratory data analysis, some potential columns to use in machine learning modeling are:\n",
        "\n",
        "- Oldpeak\n",
        "- MaxHR\n",
        "- Age\n",
        "- FastingBS\n",
        "- ST slope\n",
        "- Exercise angina\n",
        "- Cholesterol\n",
        "\n",
        "OBS: Even though Cholesterol didn't show a higher correlation with HeartDisease, it was expected by [domain knowledge](), which states that the risk of dying of heart disease has a non-linear correlation with cholesterol. With that in mind, we also included it as one of the features.\n",
        "\n",
        "ST slope and Exercise angina do not show in the correlation table.That is expected since they are categorical variables and need to be transformed into dummy indices. Let's do that and check if we guessed it right:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WPJxx8IWqd6Y"
      },
      "outputs": [],
      "source": [
        "# Replace categorical values for the 'Sex' feature\n",
        "heartDF['Sex'] = heartDF['Sex'].apply(lambda x: 0 if x == 'M' else 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OpufJiXZpkCx"
      },
      "outputs": [],
      "source": [
        "# Replace categorical values for the 'ExerciseAngina' feature\n",
        "heartDF['ExerciseAngina'] = heartDF['ExerciseAngina'].apply(lambda x : 1 if x == 'Y' else 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9oYhUJHe0zW"
      },
      "outputs": [],
      "source": [
        "# Create dummy variables for the categorical features 'ChestPainType', 'RestingECG' and 'ST_Slope'\n",
        "heartDF = pd.get_dummies(data = heartDF, columns = ['ChestPainType','RestingECG','ST_Slope'], drop_first= True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXgQ0yaygSn5",
        "outputId": "a60cc635-9115-4a5a-f9e1-bbcf2c94e3aa"
      },
      "outputs": [],
      "source": [
        "# Compute Pearson's r coefficient\n",
        "abs(heartDF.corr()['HeartDisease']).nlargest(n=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCcYSjQjbyRr"
      },
      "source": [
        "As we predicted from the data exploration, there is a high correlation between CVD with ST_Slope and ExerciseAngina."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QoowFT3Eg7dV",
        "outputId": "e576a0df-aa64-48c5-e536-6145e6845889"
      },
      "outputs": [],
      "source": [
        "sns.heatmap(heartDF.corr())\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgYt57v4homI"
      },
      "source": [
        "If we follow just Pearson's correlation values, we should choose the following nine features for modeling:\n",
        "\n",
        "- ST_Slope_Up          \n",
        "- ST_Slope_Flat        \n",
        "- ExerciseAngina  \n",
        "- Oldpeak              \n",
        "- ChestPainType_ATA    \n",
        "- MaxHR                \n",
        "- Sex              \n",
        "- Age                  \n",
        "- FastingBS\n",
        "\n",
        "However, from the heatmap:\n",
        "\n",
        "1 - ST_Slope_Up and ST_Slope_Flat are strongly correlated, so we can choose only one of these features and avoid redundancies. \n",
        "\n",
        "2 - Age has a strong correlation with ST_Slope_Up, RestingECG_Normal, ChestPainType_ATA, and MaxHR. \n",
        "\n",
        "3 - Sex has a strong correlation with ExerciseAngina and Oldpeak and FastingBS. Since Sex is an uneven variable, we will not use it to exclude possible features to train the model.\n",
        "\n",
        "4 - FastingBS has a strong correlation with ST_Slope_UP, RestingECG_Normal, ChestPainType_ATA, and MaxHR.\n",
        "\n",
        "We are left with the following features:\n",
        "\n",
        "- ST_Slope_Flat\n",
        "- ExerciseAngina\n",
        "- Oldpeak\n",
        "- Sex\n",
        "- Age\n",
        "- FastingBS\n",
        "- Cholesterol\n",
        "\n",
        "\n",
        "#### Split-Apply-Combine method for feature selection\n",
        "\n",
        "To double-check, if we found an optimal choice of features, we will use the split-apply-combine method to check for the values of the means of all features grouped by the target variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6F292aXFdIfm",
        "outputId": "a1f3da82-09f6-441e-857f-4d5099f51006"
      },
      "outputs": [],
      "source": [
        "# Split-apply-combine method\n",
        "heartDF.groupby('HeartDisease').agg(\n",
        "    {\n",
        "        'ST_Slope_Up': 'mean',         \n",
        "        'ST_Slope_Flat': 'mean',        \n",
        "        'ExerciseAngina': 'mean',\n",
        "        'Oldpeak': 'mean',\n",
        "        'ChestPainType_ATA': 'mean',\n",
        "        'MaxHR': 'mean',           \n",
        "        'Sex': 'mean',\n",
        "        'Age': 'mean',\n",
        "        'FastingBS': 'mean',\n",
        "        'ChestPainType_NAP': 'mean',\n",
        "        'RestingBP': 'mean',\n",
        "        'RestingECG_ST': 'mean',\n",
        "        'RestingECG_Normal': 'mean',\n",
        "        'Cholesterol': 'mean',\n",
        "        'ChestPainType_TA': 'mean'  \n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5N5Ff3HjgX8v"
      },
      "source": [
        "The split-apply-combine procedure shows a reasonable separation between the mean values for the ChestPainType_NAP feature. That suggests it could be a potential variable for modeling as well. However, the correlation coefficient and our exploratory analysis pointed out against it. So we will use only the features selected in the previous section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCnzbodvvDcj"
      },
      "source": [
        "# Building a classifier\n",
        "\n",
        "We will use accuracy as our metric in this project. It is a standard metric when the label for the target variable is evenly distributed, as is the case here. However, it does not account for errors (false positives and false negatives). In medicine, a false positive means a patient that tested positive but does not suffer from the disease. It can distress the patient psychologically and physically since it might require extra, more intrusive tests to confirm the diagnosis. A false negative could mean the patient's death. Having that in mind, we will also explore [alternative metrics](https://colab.research.google.com/drive/1i7Y8YV_nQxqVEsoBVU7hI219bE2-I3wB#scrollTo=jxoC9aBI3gZU) to guide us along this project.\n",
        "\n",
        "We will build different models for predicting CVDs, starting with the K-nearest neighbors algorithm.\n",
        "\n",
        "## K-Nearest Neighbors classifier\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5jH5HQ5HDPHw"
      },
      "outputs": [],
      "source": [
        "# Defining feature and target spaces\n",
        "X = heartDF[['ST_Slope_Up','ExerciseAngina','Oldpeak', 'Sex', 'Age', 'FastingBS', 'Cholesterol']]\n",
        "y = heartDF['HeartDisease']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BM0UTE-CCRjQ"
      },
      "outputs": [],
      "source": [
        "# Split data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state = 48, stratify= X['Sex'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tv4bjsbaGh0n"
      },
      "outputs": [],
      "source": [
        "# Split part of the train set (20% of X) as test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.2*X.shape[0]/X_train.shape[0], random_state = 48, stratify= X_train['Sex'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0L6j_nzTUC-"
      },
      "source": [
        "We used stratify for the 'Sex' feature to ensure the uneven representation of males and females on the original dataset is kept once we split the data into training, validation, and test sets. It avoids introducing extra bias in the model (more males in the training set could lead to better accuracy in the validation set but would underperform in the test set, which would have more females, for example).\n",
        "\n",
        "Before checking how the model performs using all features, we will test it in each of the features below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ie4BYkbfTR9P",
        "outputId": "57b87fce-5cd9-4783-eeab-4ec0a0145254"
      },
      "outputs": [],
      "source": [
        "features = ['ST_Slope_Up','ExerciseAngina','Oldpeak', 'Sex', 'Age', 'FastingBS','Cholesterol']\n",
        "\n",
        "for feature in features:\n",
        "  # Instantiate a knn classifier \n",
        "  knn = KNeighborsClassifier(n_neighbors= 5)\n",
        "  knn.fit(X_train[[feature]], y_train)\n",
        "  score = knn.score(X_val[[feature]], y_val)\n",
        "  print(f'The accuracy on the validation set, using only the {feature} feature was {score*100:.2f}%.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJEabjdpV1rC"
      },
      "source": [
        "Among the models built with only one feature, we had:\n",
        "\n",
        "- The 'ST_Slop_Up' feature with the highest correlation with the target variable also provided the best model with 73.91% accuracy on the validation set. \n",
        "\n",
        "- The model using only the 'Oldpeak' feature performed worse (68.48% accuracy on the validation set) than the models using only the 'Sex' feature (70.11% accuracy) even though Oldpeak has a significantly higher linear correlation with the target variable.\n",
        "\n",
        "- Surprisingly, the 'Age' feature had the worse performance (50% accuracy).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtdphA3AJkjw"
      },
      "source": [
        "We will now build a model using all features. The KNN algorithm uses the distances of neighbors to compute the accuracy. It is then crucial to normalize all feature values to avoid favoring the ones with more sparsed values. We will use a scaler to normalize the values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "epfLR2FYKTJN"
      },
      "outputs": [],
      "source": [
        "# Instantiate a scaler\n",
        "scaler = MinMaxScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-RjHrRbOKYX9"
      },
      "outputs": [],
      "source": [
        "# Scaling training, validation and test sets\n",
        "X_train_scaled = scaler.fit_transform(X_train[['ST_Slope_Up','ExerciseAngina','Oldpeak', 'Sex', 'Age', 'FastingBS','Cholesterol']])\n",
        "X_val_scaled = scaler.fit_transform(X_val[['ST_Slope_Up','ExerciseAngina','Oldpeak', 'Sex', 'Age', 'FastingBS','Cholesterol']])\n",
        "X_test_scaled = scaler.fit_transform(X_test[['ST_Slope_Up','ExerciseAngina','Oldpeak', 'Sex', 'Age', 'FastingBS','Cholesterol']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytjbvIHKNRog",
        "outputId": "5ca9ff20-da88-460a-bccb-786bf1b4149a"
      },
      "outputs": [],
      "source": [
        "# Building a model with all features and testing its accuracy on the validation test\n",
        "knn = KNeighborsClassifier(n_neighbors= 5)\n",
        "knn.fit(X_train_scaled, y_train)\n",
        "score = knn.score(X_val_scaled, y_val)\n",
        "print(f'The accuracy on the validation set, using all features was: {score*100:.2f}%.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WY8kDnjUDNUq"
      },
      "source": [
        "The accuracy, using all features, was 79.9%. It improved in relation to the 73.9% accuracy using only the ST_Slope_Up feature. However, we can try to do better by using GridSearch.\n",
        "\n",
        "## Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFdWwrHTFjRC"
      },
      "outputs": [],
      "source": [
        "# Define parameter space\n",
        "grid_params = {'n_neighbors': range(1,100), \n",
        "               'p': [1, 2, 3]}\n",
        "\n",
        "# Instantiate a classifier\n",
        "knn = KNeighborsClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2gPt3OCN9GG",
        "outputId": "5c40203c-bd66-490a-f280-61656d86d1ab"
      },
      "outputs": [],
      "source": [
        "# Search for best parameters\n",
        "knn_grid = GridSearchCV(knn, param_grid= grid_params, scoring = 'accuracy')\n",
        "\n",
        "# Fit model using best parameters\n",
        "knn_grid.fit(X_train_scaled, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOcPYu5c5rT_",
        "outputId": "12c6ffe4-51ae-4fc7-dfaf-e721a328f6f5"
      },
      "outputs": [],
      "source": [
        "# Check the metric used for the scoring\n",
        "knn_grid.scorer_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-XRoPgvPWPU",
        "outputId": "929ef8e0-2723-4ee8-e1ec-431f84c1b376"
      },
      "outputs": [],
      "source": [
        "# print best parameters and score\n",
        "print(f'The best parameters were given by {knn_grid.best_params_}.')\n",
        "print(f'The best score was {knn_grid.best_score_*100:.2f}%.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8d-p3EBbP-SW"
      },
      "source": [
        "- With 39 neighbors and p = 1 (Manhattan metric), the best model had an f1-score of ~87.3%. \n",
        "\n",
        "- It delivered a better result than the model we built using only 5 neighbors and p=2. \n",
        "\n",
        "- GridSearch performs cross-validation under the hood and is more likely to better estimate how the model will perform in the test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvsFMR-dQQGa"
      },
      "source": [
        "## Model evaluation on test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4ug0MYCVnEx"
      },
      "outputs": [],
      "source": [
        "# Find score for test set\n",
        "accuracy = knn_grid.best_estimator_.score(X_test_scaled,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEdAviILV_UG",
        "outputId": "e56d7c4a-420d-4f56-8fef-c326e5bac5a9"
      },
      "outputs": [],
      "source": [
        "print(f'The model accuracy on the test set was {accuracy*100:.2f}%.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRjRJ_AbWP2D"
      },
      "source": [
        "The model's accuracy was ~87% on the test set. Very close to the 87.3%  obtained using the training set with GridSearch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "366JjDf8WobE"
      },
      "source": [
        "## Logistic regression\n",
        "\n",
        "We start building a logistic regression model using the train_test_split method from sklearn. We will use it to compute the accuracy, sensitivity, specificity, PPV, and NPV metrics. We will also use it to analyze the model's coefficients and check if the chosen features will contribute to the model's performance.\n",
        "\n",
        "Later, we will perform cross-validation to obtain more realistic values for the model's accuracy. We will also compute the [f1-score](https://colab.research.google.com/drive/1i7Y8YV_nQxqVEsoBVU7hI219bE2-I3wB#scrollTo=jxoC9aBI3gZU), which contains information about the wrong predictions made by the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vb1biLECquB_"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Split features and target\n",
        "X = heartDF[['ST_Slope_Up','ExerciseAngina','Oldpeak', 'Sex', 'Age', 'FastingBS', 'Cholesterol']]\n",
        "y = heartDF['HeartDisease']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LX6dL25lq6Cb"
      },
      "outputs": [],
      "source": [
        "# Split into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size= 0.2, random_state= 48, stratify= X['Sex'])\n",
        "\n",
        "# Split the training set into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train,y_train, test_size = 0.2*X.shape[0]/X_train.shape[0], random_state = 48, stratify = X_train['Sex'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8We_NbsrpgO",
        "outputId": "9c68aea2-a0e8-4a42-d175-65003a156f0e"
      },
      "outputs": [],
      "source": [
        "# Instantiate a model\n",
        "lr = LogisticRegression(max_iter = 200)\n",
        "\n",
        "# Fit logistic regression model\n",
        "lr.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eD8cjZdMsFsG",
        "outputId": "8aa78cf1-9928-48f3-8b8c-ae0eba974139"
      },
      "outputs": [],
      "source": [
        "# Compute accuracy validation set\n",
        "accuracy_val = lr.score(X_val, y_val)\n",
        "print(f'The accuracy on the validation set was {accuracy_val*100:.2f}%.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5P4rVqP0I-u"
      },
      "source": [
        "We did split the data into training, validation, and test sets. It is good practice to do so once we start iterating the model. However, in this project, we will stick with the features we chose and move on to check the accuracy of the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yw95p2pIz-0U",
        "outputId": "c9f58d88-1bcd-4478-c121-172d06531d64"
      },
      "outputs": [],
      "source": [
        "# Accuracy on the test set\n",
        "accuracy_test = lr.score(X_test,y_test)\n",
        "\n",
        "print(f'The accuracy on the test set was: {accuracy_test*100:.2f}%.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7X09AHDzt18E"
      },
      "source": [
        "The model's performance on the validation set for the logistic regression model was the same as on the validation set using the K-NN algorithm (~79.9% accuracy). It was considerably faster to train a logistic regression model than a K-NN algorithm. However, K-NN took longer due to the cross-validation and the grid search, which tends to be more precise than a single split into training, validation, and test sets that we used for the logistic regression model.\n",
        "\n",
        "Another problem with not performing cross-validation is that the values for the accuracy of the validation and test sets are very different as we noticed above. The mean of the cross-validation scores tends to be a more realistic score on new data. We will perform cross-validation in the next section.\n",
        "\n",
        "\n",
        "Let's compute the sensitivity, specificity, positive predictive value, and negative predictive values for this model. It will help us to understand the  f1-score result later on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0RXyRZIuuJA",
        "outputId": "bacab6c0-ef73-4ace-e24e-54d28e42ac8a"
      },
      "outputs": [],
      "source": [
        "# Compute true positives\n",
        "tp = sum((lr.predict(X_train) == 1) & (y_train ==1))\n",
        "print(f'The number of true positives was, {tp}.')\n",
        "\n",
        "# Compute true negatives\n",
        "tn = sum((lr.predict(X_train) == 0) & (y_train == 0))\n",
        "print(f'The number of true negatives was {tn}.')\n",
        "\n",
        "# Compute false positives\n",
        "fp = sum((lr.predict(X_train) == 1) & (y_train == 0))\n",
        "print(f'The number of false positives was, {fp}.')\n",
        "\n",
        "# Compute false negatives\n",
        "fn = sum((lr.predict(X_train) == 0) & (y_train == 1))\n",
        "print(f'The number of false negatives was, {fn}.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iksztsZWwzJh",
        "outputId": "6cf9dd46-135f-480e-ce1b-2ab37cce76ca"
      },
      "outputs": [],
      "source": [
        "# Compute sensitivity\n",
        "sensitivity = tp/(tp + fn)\n",
        "print(f'The sensitivity of the model was: {sensitivity*100:.2f}%.')\n",
        "\n",
        "# Compute specificity\n",
        "specificity = tn/(tn + fp)\n",
        "print(f'The specificity of the model was: {specificity*100:.2f}%.')\n",
        "\n",
        "# Compute PPV\n",
        "PPV = tp/(tp + fp)\n",
        "print(f'The PPV of the model was: {PPV*100:.2f}%.')\n",
        "\n",
        "# Compute NPV\n",
        "NPV = tn/(tn + fn)\n",
        "print(f'The NPV of the model was: {NPV*100:.2f}%.')\n",
        "\n",
        "# F1-score\n",
        "\n",
        "f1_score = 2*sensitivity*PPV/(sensitivity + PPV)\n",
        "print(f'The f1-score for this model is: {NPV*100:.2f}%.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OGZm3eFxuOw"
      },
      "source": [
        "The model has a sensitivity of 89.40%. A model with high sensitivity is useful to rule out a positive outcome. In other words, [a model with high sensitivity generally has a high NPV](https://colab.research.google.com/drive/1i7Y8YV_nQxqVEsoBVU7hI219bE2-I3wB). In fact, a patient predicted as negative for CDV using this model has an 86.72% chance of being negative. \n",
        "\n",
        "On the other side, the model had a specificity of 84.27%. It is also not bad. [A model with high specificity generally has a high PPV](https://colab.research.google.com/drive/1i7Y8YV_nQxqVEsoBVU7hI219bE2-I3wB) In fact, patients that predicted as positive for CDV using this model have an 87.38% chance of being positive.\n",
        "\n",
        "#### Logistic regression parameters\n",
        "\n",
        "To interpret the logistic regression parameters, we need to remember how the features impact the probability of predicting a label for the outcome. That is given by:\n",
        "$$\n",
        "log(\\frac{EY}{1-EY}) = \\alpha + \\beta*X.\n",
        "$$\n",
        "From this we can [derive](https://colab.research.google.com/drive/1Ksc9An1H85_zUSm90EtZqHdcp85kKH-Z#scrollTo=yhfjjFpApfbv) that the slope $\\beta$ is given by:\n",
        "$$\n",
        "\\beta = log(\\frac{Odds(1)}{Odds(0)}),\n",
        "$$\n",
        "or\n",
        "$$\n",
        "\\frac{Odds(1)}{Odds(0)} = e^{\\beta},\n",
        "$$\n",
        "where\n",
        "$$\n",
        "Odds(y) = \\frac{EY(y)}{1-EY(y)}.\n",
        "$$\n",
        "Let's obtain the slope from the logistic regression model and compute the odds ratio:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ht-KxzQu0i_N",
        "outputId": "5d2c72ca-e808-4ad7-bba3-57494b9739cd"
      },
      "outputs": [],
      "source": [
        "# Retrieve the slope\n",
        "beta = lr.coef_\n",
        "\n",
        "# Compute odds ratio\n",
        "odds_ratio = np.exp(beta)\n",
        "\n",
        "print(f'The odds ratio for the logistic regression model are: \\n ST_Slope_Up: {odds_ratio[0,0]:.4f}, \\n ExerciseAngina: {odds_ratio[0,1]:.4f}, \\n Oldpeak: {odds_ratio[0,2]:.4f}, \\n Sex: {odds_ratio[0,3]:.4f}, \\n Age: {odds_ratio[0,4]:.4f},  \\n FastingBS: {odds_ratio[0,5]:.4f}, \\n Cholesterol: {odds_ratio[0,6]:.4f}.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PryDUPH6kcM"
      },
      "source": [
        "These results make sense. Most of the features have an odds ratio higher than 1. In other words, it is exponentially more likely to have a patient diagnosed as positive if we increase the values for the features by one unit. \n",
        "\n",
        "ST_Slope_Up and Sex are categorical variables and do not carry the same meaning as a numerical variable. For example, we are considering the value 0 for male patients and 1 for females. That explains why the odds ratio is smaller than 1. Analogously, for the ST_Slope_Up variable, as one can see from the split-apply-combine section. A higher value for this variable is correlated with negative predictions, while smaller values are correlated with positive predictions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBG-ojeuBwm1"
      },
      "source": [
        "### KFold cross-validation\n",
        "\n",
        "We will use the [cross_validate](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html) class from sklearn to implement cross-validation and obtain a more realistic value for the accuracy and f1-score metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqWd9OHzLs2G",
        "outputId": "4cf2431d-84e8-44ea-ee65-b0c9a24a4b61"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "# Instantiate a model\n",
        "model = LogisticRegression(max_iter =200)\n",
        "\n",
        "# Perform cross-validation and compute accuracy and f1-score for the model\n",
        "multiple_cross_scores = cross_validate(model, \n",
        "                                       X, y, cv = 10,\n",
        "                                       scoring = ('accuracy', 'f1'))\n",
        "\n",
        "print(multiple_cross_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msuWwYGLRuqC",
        "outputId": "dbcf1c70-4826-46d7-e671-c988448df824"
      },
      "outputs": [],
      "source": [
        "# Average accuracy\n",
        "accuracy_cross_val = multiple_cross_scores['test_accuracy'].mean()\n",
        "print(f'The average accuracy for the logistic regression model, after performing cross-validation, was: {accuracy_cross_val*100:.2f}%.')\n",
        "\n",
        "# Average f1-score\n",
        "f1_cross_val = multiple_cross_scores['test_f1'].mean()\n",
        "print(f'The average f1-score for the logistic regression model, after performing cross-validation, was: {f1_cross_val*100:.2f}%.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Za6KJm_Kt_cR"
      },
      "source": [
        "The accuracy value for the logistic regression model we created was 83.65%. In other words, the model predicted the correct labels, either positive or negative, in 83.65% of the cases. The f1-score was 85.16%, indicating good sensitivity and positive predictive values. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVeT1YQY81IQ"
      },
      "source": [
        "# Summary\n",
        "\n",
        "In this project, we explored, cleaned, and selected features from patients suspected of suffering from cardiovascular diseases (CVDs). We used the cleaned data to build a K-nearest neighbor and a logistic regression model. The highlights from these models are:\n",
        "\n",
        "- The K-NN model had better performance with an accuracy of ~87.0% on the test against the ~83.6% accuracy for the logistic regression.\n",
        "\n",
        "- The logistic regression model had an f1-score of 85.16%. It indicates the model is good at selecting positive patients. This model could be relevant in a [screening procedure](https://colab.research.google.com/drive/1i7Y8YV_nQxqVEsoBVU7hI219bE2-I3wB), for example.\n",
        "\n",
        "- In a real-world scenario, this model performance is not ideal. 87.0% accuracy looks good, but it would mean that 13.0% of the patients got the wrong result. A false positive could distress the patient and lead him/her on a path for treatments that are not needed. A false negative could mean death!\n",
        "\n",
        "- For the logistic regression model, the f1-score was higher than the accuracy. It is an indication that the model is better at detecting positive cases. That's a desirable feature in medicine. However, ideally, we don't want to misclassify any patients. That could be implemented by increasing the number of labels for the outcomes, which would lead to a multi-class classification problem. That is beyond the scope of this project.\n",
        "\n",
        "# Future directions\n",
        "\n",
        "- We could increase the parameter space to improve the models' performance, collect more data or improve the feature selection before building the classifiers. Feature engineering could also help to improve the performance of a model.\n",
        "\n",
        "- Increase the number of labels for the outcomes. That could improve the quality of the diagnostics by, for example, sending borderline patients for extra tests."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HwoIP4a3Blje"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOcZTTNFFljoUapPPwGpbKM",
      "collapsed_sections": [
        "Pv_ILKunSQoG",
        "05NdOTKDSgn_",
        "dMw2cE0NSvK_",
        "NhvxfBSLSyD_",
        "IpLewTUjTCXe",
        "VyxquzdbTFpR",
        "0EOrirHKi4L1",
        "QL2i9wYmQmEh",
        "t6m42N5yjc00",
        "pTnu2-KqmaL6"
      ],
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
